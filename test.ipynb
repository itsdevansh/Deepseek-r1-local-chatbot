{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully: client=<openai.resources.chat.completions.Completions object at 0x1189ce850> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x118c75c10> root_client=<openai.OpenAI object at 0x10f28ced0> root_async_client=<openai.AsyncOpenAI object at 0x118c74e50> model_name='gpt-4o-mini' temperature=0.3 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from app.chatbot.event_handler import create_event, get_events, update_event, delete_event\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.types import interrupt, Command\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "tools = [create_event, get_events, update_event, delete_event]\n",
    "\n",
    "# Initialize the model\n",
    "def init_model() -> ChatOpenAI:\n",
    "    try:\n",
    "        MODEL_NAME = os.getenv(\"MODEL_NAME\")\n",
    "        OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "        llm = ChatOpenAI(\n",
    "            model=MODEL_NAME,\n",
    "            temperature=0.3,\n",
    "            api_key=OPENAI_API_KEY,\n",
    "        )\n",
    "        \n",
    "        # llm.format = \"json\"\n",
    "        print(\"Model initialized successfully:\", llm)\n",
    "        return llm\n",
    "    except Exception as e:\n",
    "        print(f\"Model cannot be initialized: {e}\")\n",
    "\n",
    "llm = init_model()\n",
    "    \n",
    "def human_in_the_loop(state: dict):\n",
    "    human = interrupt(state[\"messages\"][-1].content)\n",
    "    # information = \"It is a personal meeting from 1 pm to 2pm and no attendees.\"\n",
    "    state[\"messages\"].append(HumanMessage(human))\n",
    "    return state\n",
    "\n",
    "# Define the agent node\n",
    "def agent_node(state: dict):\n",
    "\n",
    "    try:\n",
    "        # Validate the state structure\n",
    "        # if not isinstance(state, dict) or \"context\" not in state or \"messages\" not in state:\n",
    "        #     raise ValueError(\"State must be a dictionary with 'context' and 'messages' keys\")\n",
    "\n",
    "        # llm = state[\"context\"][\"llm\"]\n",
    "        # tools = state[\"context\"][\"tools\"]\n",
    "        # if not llm or not tools:\n",
    "        #     raise ValueError(\"LLM or tools missing from context\")\n",
    "        \n",
    "        prompt = \"\"\"\n",
    "        You are a helpful assistant that can create, list, update, and delete google calendar events.\n",
    "        You are in Eastern Standard Time Zone.\n",
    "        Extract all the information from the user message and for information that is missing, ask the user for it causing least friction. Whenever you need data from the user, always ask the question starting with the phrase 'Human'.\"\n",
    "        Assume data generously\n",
    "        While updating or deleting events, get all the events for the mentioned date from 12am to 11:59pm. Use the id of that particular event to perform the necessary action.\"\"\"\n",
    "    \n",
    "        llm = init_model()\n",
    "\n",
    "        graph_agent = create_react_agent(llm, tools=tools, state_modifier=prompt)\n",
    "        result = graph_agent.invoke(state)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in agent_node: {e}\")\n",
    "        return state\n",
    "\n",
    "# Print stream function\n",
    "def print_stream(stream):\n",
    "    try:\n",
    "        for s in stream:\n",
    "            if isinstance(s, dict):\n",
    "                # Handle \"branch\" condition\n",
    "                if \"branch\" in s:\n",
    "                    print(f\"Branch condition met: {s['branch']}\")\n",
    "                # Handle messages from \"agent\"\n",
    "                elif \"agent\" in s and \"messages\" in s[\"agent\"]:\n",
    "                    message = s[\"agent\"][\"messages\"][-1]\n",
    "                    if \"AIMessage\" in str(type(message)):  # Check if it's an AIMessage\n",
    "                        print(message.content)\n",
    "                else:\n",
    "                    print(\"Other stream output:\", s)\n",
    "            else:\n",
    "                print(\"Unexpected stream format:\", s)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in print_stream: {e}\")\n",
    "        \n",
    "# Main workflow\n",
    "\n",
    "# Tools for handling events\n",
    "tools = [create_event, get_events, update_event, delete_event]\n",
    "\n",
    "# User input message\n",
    "user_message = \"Can you create an event on 26 January 2025 for a meeting at 110 Stewart Street?\"\n",
    "# user_message = \"Can you list all the events I have on the 26 January 2025?\"\n",
    "# user_message = \"Can you delete all the event on the 27 January 2025?\"\n",
    "# user_message = \"Can you list all the events I have on the 27 January 2025? and then create an event on 27 jan 2025 from 5pm to 6pm for a meeting at 110 stewart street\"\n",
    "# user_message = \"Can you delete the Meeting on 26th Jan 2025?\"\n",
    "\n",
    "\n",
    "# Initialize workflow state\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [(\"user\", user_message)],\n",
    "}\n",
    "\n",
    "def route(state: dict):\n",
    "    if \"Human\" in state[\"messages\"][-1].content:\n",
    "        return \"Human_Input\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "\n",
    "\n",
    "# events = graph.stream(initial_state, config={\"configurable\": {\"thread_id\": \"1\"}})\n",
    "\n",
    "# Print results\n",
    "# print_stream(events)\n",
    "\n",
    "\n",
    "\n",
    "# Resume using Command\n",
    "# while \"__interrupt__\" in chunk:\n",
    "#     for chunk in graph.stream(Command(resume=input(\"Enter additional info: \")), config=config):\n",
    "#             print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateSnapshot(values={}, next=(), config={'configurable': {'thread_id': '1'}}, metadata=None, created_at=None, parent_config=None, tasks=())\n",
      "Model initialized successfully: client=<openai.resources.chat.completions.Completions object at 0x118c3e410> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x118cf7950> root_client=<openai.OpenAI object at 0x10f52d310> root_async_client=<openai.AsyncOpenAI object at 0x118cdbe90> model_name='gpt-4o-mini' temperature=0.3 model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "{'agent': {'messages': [HumanMessage(content='Can you create an event on 26 January 2025 for a meeting at 110 Stewart Street?', additional_kwargs={}, response_metadata={}, id='e64ab463-aa71-49fe-9573-e1a878dd3cb0'), AIMessage(content=\"Human, could you please provide me with the summary of the meeting, the start time, the end time, and any attendees' emails you'd like to include?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 596, 'total_tokens': 630, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-76ad4059-0765-46cc-81db-7f0d1b4e304e-0', usage_metadata={'input_tokens': 596, 'output_tokens': 34, 'total_tokens': 630, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "Can you create an event on 26 January 2025 for a meeting at 110 Stewart Street?\n",
      "Human, could you please provide me with the summary of the meeting, the start time, the end time, and any attendees' emails you'd like to include?\n"
     ]
    }
   ],
   "source": [
    "# Create the workflow\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "# workflow.add_node(\"Human_Input\", human_in_the_loop)\n",
    "workflow.add_edge(START, \"agent\")\n",
    "# workflow.add_edge(\"Human_Input\",\"agent\")\n",
    "# workflow.add_conditional_edges(\"agent\", route)\n",
    "workflow.add_edge(\"agent\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "# Compile and execute\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "print(graph.get_state(config))\n",
    "\n",
    "# Using stream() to directly surface the `__interrupt__` information.\n",
    "for chunk in graph.stream(initial_state, config=config):\n",
    "    print(chunk)\n",
    "\n",
    "final_state = graph.get_state(config) \n",
    "for message in final_state.values[\"messages\"]:\n",
    "    print(message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully: client=<openai.resources.chat.completions.Completions object at 0x1179aa210> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x1179a5f50> root_client=<openai.OpenAI object at 0x1179aa490> root_async_client=<openai.AsyncOpenAI object at 0x11795f510> model_name='gpt-4o-mini' temperature=0.3 model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "Event created: https://www.google.com/calendar/event?eid=ZnFqajJkdjRjbjVtZzV1MHA1bmc3NjU5M2tfMjAyNTAxMjZUMTkwMDAwWiByb2hpdHNoZWxrZTExQG0\n",
      "{'agent': {'messages': [HumanMessage(content='Can you create an event on 26 January 2025 for a meeting at 110 Stewart Street?', additional_kwargs={}, response_metadata={}, id='8e5efd0a-330a-414a-9336-2eb7bbd87b62'), AIMessage(content='Human, could you please provide me with the summary of the meeting, the description, the start time, and the end time for the event on 26 January 2025? Additionally, if there are any attendees, please share their email addresses.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 596, 'total_tokens': 648, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-c5530758-65bb-4064-95a3-7eda385b5c1b-0', usage_metadata={'input_tokens': 596, 'output_tokens': 52, 'total_tokens': 648, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='It is a personal meeting from 2pm to 3pm and no attendees.', additional_kwargs={}, response_metadata={}, id='c0b7e4cf-e8a1-4600-b228-f699aa3f0789'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ErFFZJTjCh9gOPqWyizNaav1', 'function': {'arguments': '{\"summary\":\"Personal Meeting\",\"location\":\"110 Stewart Street\",\"description\":\"A personal meeting.\",\"start_time\":\"2025-01-26T14:00:00-05:00\",\"end_time\":\"2025-01-26T15:00:00-05:00\",\"attendees\":[]}', 'name': 'create_event'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 671, 'total_tokens': 743, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5812f093-6381-4d22-b789-1442942c60d5-0', tool_calls=[{'name': 'create_event', 'args': {'summary': 'Personal Meeting', 'location': '110 Stewart Street', 'description': 'A personal meeting.', 'start_time': '2025-01-26T14:00:00-05:00', 'end_time': '2025-01-26T15:00:00-05:00', 'attendees': []}, 'id': 'call_ErFFZJTjCh9gOPqWyizNaav1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 671, 'output_tokens': 72, 'total_tokens': 743, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Event created: https://www.google.com/calendar/event?eid=ZnFqajJkdjRjbjVtZzV1MHA1bmc3NjU5M2tfMjAyNTAxMjZUMTkwMDAwWiByb2hpdHNoZWxrZTExQG0', name='create_event', id='3c659383-c15e-4c77-9b6d-75500db85b6d', tool_call_id='call_ErFFZJTjCh9gOPqWyizNaav1'), AIMessage(content='The personal meeting has been successfully created for 26 January 2025 from 2 PM to 3 PM at 110 Stewart Street. You can view the event [here](https://www.google.com/calendar/event?eid=ZnFqajJ2dHc3NjU5M2tfMjAyNTAxMjZUMTkwMDAwWiByb2hpdHNoZWxrZTExQG0).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 819, 'total_tokens': 912, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-0a21ed1a-a5b1-4341-8c23-de6af68474db-0', usage_metadata={'input_tokens': 819, 'output_tokens': 93, 'total_tokens': 912, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "final_state.values[\"messages\"].append(HumanMessage(\"It is a personal meeting from 2pm to 3pm and no attendees.\"))\n",
    "\n",
    "for chunk in graph.stream(final_state.values, config=config):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you create an event on 26 January 2025 for a meeting at 110 Stewart Street?\n",
      "Human, could you please provide me with the summary of the meeting, the description, the start time, and the end time for the event on 26 January 2025? Additionally, if there are any attendees, please share their email addresses.\n",
      "It is a personal meeting from 2pm to 3pm and no attendees.\n",
      "\n",
      "Event created: https://www.google.com/calendar/event?eid=ZnFqajJkdjRjbjVtZzV1MHA1bmc3NjU5M2tfMjAyNTAxMjZUMTkwMDAwWiByb2hpdHNoZWxrZTExQG0\n",
      "The personal meeting has been successfully created for 26 January 2025 from 2 PM to 3 PM at 110 Stewart Street. You can view the event [here](https://www.google.com/calendar/event?eid=ZnFqajJ2dHc3NjU5M2tfMjAyNTAxMjZUMTkwMDAwWiByb2hpdHNoZWxrZTExQG0).\n"
     ]
    }
   ],
   "source": [
    "final_state = graph.get_state(config) \n",
    "for message in final_state.values[\"messages\"]:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stale smell of old beer lingers. It takes heat to bring out the odor. A cold dip restores health and zest. A salt pickle tastes fine with ham. Tacos al pastor are my favorite. A zestful food is the hot cross bun.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file= open(\"harvard.wav\", \"rb\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file)\n",
    "\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
